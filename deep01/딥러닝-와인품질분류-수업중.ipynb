{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d308a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시드 고정:  12\n"
     ]
    }
   ],
   "source": [
    "# 필수 라이브러리\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "# 랜덤 시드 고정\n",
    "SEED=12\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)  \n",
    "print(\"시드 고정: \", SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4198885b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5497, 14)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/train.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5569432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>quality</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.06</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.042</td>\n",
       "      <td>9.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.99432</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.2</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.067</td>\n",
       "      <td>10.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99690</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.59</td>\n",
       "      <td>9.5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.39</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.057</td>\n",
       "      <td>21.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.99176</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.52</td>\n",
       "      <td>10.9</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.31</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.046</td>\n",
       "      <td>29.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.99390</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10.8</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.26</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.059</td>\n",
       "      <td>32.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.99550</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.43</td>\n",
       "      <td>10.9</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5492</th>\n",
       "      <td>5492</td>\n",
       "      <td>5</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.029</td>\n",
       "      <td>10.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.99320</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.39</td>\n",
       "      <td>10.1</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5493</th>\n",
       "      <td>5493</td>\n",
       "      <td>6</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.034</td>\n",
       "      <td>26.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99074</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.51</td>\n",
       "      <td>11.0</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5494</th>\n",
       "      <td>5494</td>\n",
       "      <td>7</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.035</td>\n",
       "      <td>31.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.99096</td>\n",
       "      <td>3.07</td>\n",
       "      <td>0.72</td>\n",
       "      <td>11.3</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5495</th>\n",
       "      <td>5495</td>\n",
       "      <td>5</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.042</td>\n",
       "      <td>18.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.99195</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.41</td>\n",
       "      <td>10.5</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5496</th>\n",
       "      <td>5496</td>\n",
       "      <td>6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.049</td>\n",
       "      <td>7.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.99297</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.36</td>\n",
       "      <td>9.7</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5497 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  quality  fixed acidity  volatile acidity  citric acid  \\\n",
       "0         0        5            5.6             0.695         0.06   \n",
       "1         1        5            8.8             0.610         0.14   \n",
       "2         2        5            7.9             0.210         0.39   \n",
       "3         3        6            7.0             0.210         0.31   \n",
       "4         4        6            7.8             0.400         0.26   \n",
       "...     ...      ...            ...               ...          ...   \n",
       "5492   5492        5            7.7             0.150         0.29   \n",
       "5493   5493        6            6.3             0.180         0.36   \n",
       "5494   5494        7            7.8             0.150         0.34   \n",
       "5495   5495        5            6.6             0.410         0.31   \n",
       "5496   5496        6            7.0             0.350         0.17   \n",
       "\n",
       "      residual sugar  chlorides  free sulfur dioxide  total sulfur dioxide  \\\n",
       "0                6.8      0.042                  9.0                  84.0   \n",
       "1                2.4      0.067                 10.0                  42.0   \n",
       "2                2.0      0.057                 21.0                 138.0   \n",
       "3                6.0      0.046                 29.0                 108.0   \n",
       "4                9.5      0.059                 32.0                 178.0   \n",
       "...              ...        ...                  ...                   ...   \n",
       "5492             1.3      0.029                 10.0                  64.0   \n",
       "5493             1.2      0.034                 26.0                 111.0   \n",
       "5494             1.1      0.035                 31.0                  93.0   \n",
       "5495             1.6      0.042                 18.0                 101.0   \n",
       "5496             1.1      0.049                  7.0                 119.0   \n",
       "\n",
       "      density    pH  sulphates  alcohol   type  \n",
       "0     0.99432  3.44       0.44     10.2  white  \n",
       "1     0.99690  3.19       0.59      9.5    red  \n",
       "2     0.99176  3.05       0.52     10.9  white  \n",
       "3     0.99390  3.26       0.50     10.8  white  \n",
       "4     0.99550  3.04       0.43     10.9  white  \n",
       "...       ...   ...        ...      ...    ...  \n",
       "5492  0.99320  3.35       0.39     10.1  white  \n",
       "5493  0.99074  3.16       0.51     11.0  white  \n",
       "5494  0.99096  3.07       0.72     11.3  white  \n",
       "5495  0.99195  3.13       0.41     10.5  white  \n",
       "5496  0.99297  3.13       0.36      9.7  white  \n",
       "\n",
       "[5497 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2afe4369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       5\n",
       "1       5\n",
       "2       5\n",
       "3       6\n",
       "4       6\n",
       "       ..\n",
       "5492    5\n",
       "5493    6\n",
       "5494    7\n",
       "5495    5\n",
       "5496    6\n",
       "Name: quality, Length: 5497, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52f52d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       white\n",
       "1         red\n",
       "2       white\n",
       "3       white\n",
       "4       white\n",
       "        ...  \n",
       "5492    white\n",
       "5493    white\n",
       "5494    white\n",
       "5495    white\n",
       "5496    white\n",
       "Name: type, Length: 5497, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdf97f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4159\n",
       "0    1338\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['type'] = np.where(data['type'] == 'white', 1, 0).astype('int')\n",
    "data['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0972eecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    2416\n",
       "5    1788\n",
       "7     924\n",
       "4     186\n",
       "8     152\n",
       "3      26\n",
       "9       5\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cff9026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_data = to_categorical(data.loc[:, 'quality'] - 3)\n",
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0317e849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.6</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.06</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.042</td>\n",
       "      <td>9.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.99432</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.8</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.067</td>\n",
       "      <td>10.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99690</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.59</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.39</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.057</td>\n",
       "      <td>21.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.99176</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.52</td>\n",
       "      <td>10.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.31</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.046</td>\n",
       "      <td>29.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.99390</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.26</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.059</td>\n",
       "      <td>32.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.99550</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.43</td>\n",
       "      <td>10.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5492</th>\n",
       "      <td>7.7</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.029</td>\n",
       "      <td>10.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.99320</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.39</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5493</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.034</td>\n",
       "      <td>26.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99074</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.51</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5494</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.035</td>\n",
       "      <td>31.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.99096</td>\n",
       "      <td>3.07</td>\n",
       "      <td>0.72</td>\n",
       "      <td>11.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5495</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.042</td>\n",
       "      <td>18.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.99195</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.41</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5496</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.049</td>\n",
       "      <td>7.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.99297</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.36</td>\n",
       "      <td>9.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5497 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               5.6             0.695         0.06             6.8      0.042   \n",
       "1               8.8             0.610         0.14             2.4      0.067   \n",
       "2               7.9             0.210         0.39             2.0      0.057   \n",
       "3               7.0             0.210         0.31             6.0      0.046   \n",
       "4               7.8             0.400         0.26             9.5      0.059   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "5492            7.7             0.150         0.29             1.3      0.029   \n",
       "5493            6.3             0.180         0.36             1.2      0.034   \n",
       "5494            7.8             0.150         0.34             1.1      0.035   \n",
       "5495            6.6             0.410         0.31             1.6      0.042   \n",
       "5496            7.0             0.350         0.17             1.1      0.049   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                     9.0                  84.0  0.99432  3.44       0.44   \n",
       "1                    10.0                  42.0  0.99690  3.19       0.59   \n",
       "2                    21.0                 138.0  0.99176  3.05       0.52   \n",
       "3                    29.0                 108.0  0.99390  3.26       0.50   \n",
       "4                    32.0                 178.0  0.99550  3.04       0.43   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "5492                 10.0                  64.0  0.99320  3.35       0.39   \n",
       "5493                 26.0                 111.0  0.99074  3.16       0.51   \n",
       "5494                 31.0                  93.0  0.99096  3.07       0.72   \n",
       "5495                 18.0                 101.0  0.99195  3.13       0.41   \n",
       "5496                  7.0                 119.0  0.99297  3.13       0.36   \n",
       "\n",
       "      alcohol  type  \n",
       "0        10.2     1  \n",
       "1         9.5     0  \n",
       "2        10.9     1  \n",
       "3        10.8     1  \n",
       "4        10.9     1  \n",
       "...       ...   ...  \n",
       "5492     10.1     1  \n",
       "5493     11.0     1  \n",
       "5494     11.3     1  \n",
       "5495     10.5     1  \n",
       "5496      9.7     1  \n",
       "\n",
       "[5497 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data = data.loc[:, 'fixed acidity':]\n",
    "X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c623a215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5497, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dec49cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_max스케일링\n",
    "# 피처 스케일링\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(X_data)\n",
    "X_data_scaled = scaler.fit_transform(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6faae4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5497, 12) (5497, 7)\n"
     ]
    }
   ],
   "source": [
    "print(X_data_scaled.shape, y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4318d9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4397, 12) (4397, 7)\n",
      "(1100, 12) (1100, 7)\n"
     ]
    }
   ],
   "source": [
    "# train/test data분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data_scaled, y_data, \n",
    "                                                    test_size=0.2, \n",
    "                                                    shuffle=True, \n",
    "                                                    random_state=100)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80bc8e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9836503a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               1664      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 7)                 77        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,407\n",
      "Trainable params: 12,407\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델생성\n",
    "# 심층 신경망 모델\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "def build_model(train_data, train_target):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_dim=X_train.shape[1]))\n",
    "   # model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    # model.add(Dropout(0.1))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "    adam = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "#     model.compile(optimizer='adam', loss='categorical_crossentropy', \n",
    "#                 metrics=['acc', 'mae'])\n",
    "    \n",
    "    model.compile(optimizer= adam, loss='categorical_crossentropy', \n",
    "                metrics=['acc', 'mae'])\n",
    "    \n",
    "    return model\n",
    "model = build_model(X_train, y_train)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f7ba86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "330/330 - 0s - loss: 1.0166 - acc: 0.5577 - mae: 0.1606 - val_loss: 1.0642 - val_acc: 0.5568 - val_mae: 0.1625 - 259ms/epoch - 785us/step\n",
      "Epoch 2/200\n",
      "330/330 - 0s - loss: 1.0073 - acc: 0.5696 - mae: 0.1599 - val_loss: 1.0632 - val_acc: 0.5295 - val_mae: 0.1602 - 256ms/epoch - 776us/step\n",
      "Epoch 3/200\n",
      "330/330 - 0s - loss: 1.0000 - acc: 0.5676 - mae: 0.1594 - val_loss: 1.0597 - val_acc: 0.5591 - val_mae: 0.1581 - 332ms/epoch - 1ms/step\n",
      "Epoch 4/200\n",
      "330/330 - 0s - loss: 1.0005 - acc: 0.5770 - mae: 0.1590 - val_loss: 1.0762 - val_acc: 0.5568 - val_mae: 0.1643 - 324ms/epoch - 980us/step\n",
      "Epoch 5/200\n",
      "330/330 - 0s - loss: 1.0051 - acc: 0.5696 - mae: 0.1594 - val_loss: 1.0502 - val_acc: 0.5386 - val_mae: 0.1623 - 339ms/epoch - 1ms/step\n",
      "Epoch 6/200\n",
      "330/330 - 0s - loss: 0.9978 - acc: 0.5762 - mae: 0.1588 - val_loss: 1.0437 - val_acc: 0.5795 - val_mae: 0.1599 - 278ms/epoch - 842us/step\n",
      "Epoch 7/200\n",
      "330/330 - 0s - loss: 0.9937 - acc: 0.5757 - mae: 0.1587 - val_loss: 1.0593 - val_acc: 0.5545 - val_mae: 0.1592 - 311ms/epoch - 942us/step\n",
      "Epoch 8/200\n",
      "330/330 - 0s - loss: 0.9935 - acc: 0.5722 - mae: 0.1581 - val_loss: 1.0786 - val_acc: 0.5455 - val_mae: 0.1574 - 242ms/epoch - 732us/step\n",
      "Epoch 9/200\n",
      "330/330 - 0s - loss: 0.9865 - acc: 0.5820 - mae: 0.1574 - val_loss: 1.0574 - val_acc: 0.5545 - val_mae: 0.1621 - 273ms/epoch - 826us/step\n",
      "Epoch 10/200\n",
      "330/330 - 0s - loss: 0.9845 - acc: 0.5762 - mae: 0.1577 - val_loss: 1.0530 - val_acc: 0.5705 - val_mae: 0.1618 - 251ms/epoch - 761us/step\n",
      "Epoch 11/200\n",
      "330/330 - 0s - loss: 0.9824 - acc: 0.5764 - mae: 0.1573 - val_loss: 1.0586 - val_acc: 0.5750 - val_mae: 0.1568 - 243ms/epoch - 738us/step\n",
      "Epoch 12/200\n",
      "330/330 - 0s - loss: 0.9810 - acc: 0.5737 - mae: 0.1571 - val_loss: 1.0672 - val_acc: 0.5500 - val_mae: 0.1584 - 256ms/epoch - 776us/step\n",
      "Epoch 13/200\n",
      "330/330 - 0s - loss: 0.9780 - acc: 0.5795 - mae: 0.1565 - val_loss: 1.0831 - val_acc: 0.5227 - val_mae: 0.1639 - 240ms/epoch - 726us/step\n",
      "Epoch 14/200\n",
      "330/330 - 0s - loss: 0.9806 - acc: 0.5749 - mae: 0.1566 - val_loss: 1.0532 - val_acc: 0.5409 - val_mae: 0.1644 - 257ms/epoch - 778us/step\n",
      "Epoch 15/200\n",
      "330/330 - 0s - loss: 0.9764 - acc: 0.5795 - mae: 0.1568 - val_loss: 1.0570 - val_acc: 0.5705 - val_mae: 0.1585 - 240ms/epoch - 727us/step\n",
      "Epoch 16/200\n",
      "330/330 - 0s - loss: 0.9719 - acc: 0.5807 - mae: 0.1559 - val_loss: 1.0609 - val_acc: 0.5568 - val_mae: 0.1573 - 256ms/epoch - 777us/step\n",
      "Epoch 17/200\n",
      "330/330 - 0s - loss: 0.9696 - acc: 0.5795 - mae: 0.1556 - val_loss: 1.0513 - val_acc: 0.5636 - val_mae: 0.1586 - 238ms/epoch - 722us/step\n",
      "Epoch 18/200\n",
      "330/330 - 0s - loss: 0.9689 - acc: 0.5838 - mae: 0.1556 - val_loss: 1.0892 - val_acc: 0.5318 - val_mae: 0.1609 - 269ms/epoch - 816us/step\n",
      "Epoch 19/200\n",
      "330/330 - 0s - loss: 0.9668 - acc: 0.5800 - mae: 0.1552 - val_loss: 1.0685 - val_acc: 0.5636 - val_mae: 0.1565 - 237ms/epoch - 718us/step\n",
      "Epoch 20/200\n",
      "330/330 - 0s - loss: 0.9663 - acc: 0.5815 - mae: 0.1556 - val_loss: 1.0587 - val_acc: 0.5659 - val_mae: 0.1575 - 256ms/epoch - 777us/step\n",
      "Epoch 21/200\n",
      "330/330 - 0s - loss: 0.9608 - acc: 0.5845 - mae: 0.1549 - val_loss: 1.0787 - val_acc: 0.5432 - val_mae: 0.1541 - 233ms/epoch - 705us/step\n",
      "Epoch 22/200\n",
      "330/330 - 0s - loss: 0.9579 - acc: 0.5830 - mae: 0.1541 - val_loss: 1.0678 - val_acc: 0.5364 - val_mae: 0.1599 - 258ms/epoch - 781us/step\n",
      "Epoch 23/200\n",
      "330/330 - 0s - loss: 0.9572 - acc: 0.5916 - mae: 0.1543 - val_loss: 1.0913 - val_acc: 0.5659 - val_mae: 0.1514 - 238ms/epoch - 721us/step\n",
      "Epoch 24/200\n",
      "330/330 - 0s - loss: 0.9570 - acc: 0.5929 - mae: 0.1537 - val_loss: 1.0563 - val_acc: 0.5545 - val_mae: 0.1564 - 256ms/epoch - 777us/step\n",
      "Epoch 25/200\n",
      "330/330 - 0s - loss: 0.9480 - acc: 0.5972 - mae: 0.1527 - val_loss: 1.1075 - val_acc: 0.5477 - val_mae: 0.1600 - 249ms/epoch - 755us/step\n",
      "Epoch 26/200\n",
      "330/330 - 0s - loss: 0.9502 - acc: 0.5886 - mae: 0.1533 - val_loss: 1.0679 - val_acc: 0.5295 - val_mae: 0.1624 - 398ms/epoch - 1ms/step\n",
      "Epoch 27/200\n",
      "330/330 - 0s - loss: 0.9481 - acc: 0.5944 - mae: 0.1534 - val_loss: 1.0681 - val_acc: 0.5682 - val_mae: 0.1547 - 341ms/epoch - 1ms/step\n",
      "Epoch 28/200\n",
      "330/330 - 0s - loss: 0.9414 - acc: 0.5883 - mae: 0.1521 - val_loss: 1.0683 - val_acc: 0.5795 - val_mae: 0.1543 - 313ms/epoch - 948us/step\n",
      "Epoch 29/200\n",
      "330/330 - 0s - loss: 0.9476 - acc: 0.5881 - mae: 0.1523 - val_loss: 1.0653 - val_acc: 0.5432 - val_mae: 0.1595 - 285ms/epoch - 862us/step\n",
      "Epoch 30/200\n",
      "330/330 - 0s - loss: 0.9402 - acc: 0.5979 - mae: 0.1523 - val_loss: 1.0666 - val_acc: 0.5636 - val_mae: 0.1612 - 262ms/epoch - 794us/step\n",
      "Epoch 31/200\n",
      "330/330 - 0s - loss: 0.9349 - acc: 0.5929 - mae: 0.1520 - val_loss: 1.0498 - val_acc: 0.5545 - val_mae: 0.1566 - 329ms/epoch - 997us/step\n",
      "Epoch 32/200\n",
      "330/330 - 0s - loss: 0.9303 - acc: 0.5972 - mae: 0.1509 - val_loss: 1.0614 - val_acc: 0.5659 - val_mae: 0.1557 - 260ms/epoch - 787us/step\n",
      "Epoch 33/200\n",
      "330/330 - 0s - loss: 0.9310 - acc: 0.5977 - mae: 0.1508 - val_loss: 1.0470 - val_acc: 0.5568 - val_mae: 0.1548 - 316ms/epoch - 958us/step\n",
      "Epoch 34/200\n",
      "330/330 - 0s - loss: 0.9325 - acc: 0.5964 - mae: 0.1507 - val_loss: 1.0675 - val_acc: 0.5841 - val_mae: 0.1555 - 270ms/epoch - 819us/step\n",
      "Epoch 35/200\n",
      "330/330 - 0s - loss: 0.9217 - acc: 0.6030 - mae: 0.1502 - val_loss: 1.0835 - val_acc: 0.5568 - val_mae: 0.1561 - 266ms/epoch - 805us/step\n",
      "Epoch 36/200\n",
      "330/330 - 0s - loss: 0.9170 - acc: 0.6025 - mae: 0.1493 - val_loss: 1.0462 - val_acc: 0.5705 - val_mae: 0.1551 - 426ms/epoch - 1ms/step\n",
      "Epoch 37/200\n",
      "330/330 - 0s - loss: 0.9192 - acc: 0.6042 - mae: 0.1493 - val_loss: 1.0319 - val_acc: 0.5727 - val_mae: 0.1565 - 368ms/epoch - 1ms/step\n",
      "Epoch 38/200\n",
      "330/330 - 0s - loss: 0.9177 - acc: 0.6015 - mae: 0.1494 - val_loss: 1.0715 - val_acc: 0.5568 - val_mae: 0.1597 - 332ms/epoch - 1ms/step\n",
      "Epoch 39/200\n",
      "330/330 - 1s - loss: 0.9114 - acc: 0.6080 - mae: 0.1488 - val_loss: 1.0784 - val_acc: 0.5614 - val_mae: 0.1531 - 537ms/epoch - 2ms/step\n",
      "Epoch 40/200\n",
      "330/330 - 0s - loss: 0.9128 - acc: 0.6048 - mae: 0.1484 - val_loss: 1.0678 - val_acc: 0.5818 - val_mae: 0.1570 - 453ms/epoch - 1ms/step\n",
      "Epoch 41/200\n",
      "330/330 - 0s - loss: 0.9063 - acc: 0.6121 - mae: 0.1478 - val_loss: 1.0493 - val_acc: 0.5750 - val_mae: 0.1548 - 491ms/epoch - 1ms/step\n",
      "Epoch 42/200\n",
      "330/330 - 0s - loss: 0.9051 - acc: 0.6040 - mae: 0.1480 - val_loss: 1.0692 - val_acc: 0.5659 - val_mae: 0.1565 - 409ms/epoch - 1ms/step\n",
      "Epoch 43/200\n",
      "330/330 - 0s - loss: 0.8984 - acc: 0.6121 - mae: 0.1470 - val_loss: 1.0794 - val_acc: 0.5432 - val_mae: 0.1519 - 262ms/epoch - 794us/step\n",
      "Epoch 44/200\n",
      "330/330 - 0s - loss: 0.8958 - acc: 0.6131 - mae: 0.1463 - val_loss: 1.0569 - val_acc: 0.5500 - val_mae: 0.1537 - 249ms/epoch - 755us/step\n",
      "Epoch 45/200\n",
      "330/330 - 0s - loss: 0.8972 - acc: 0.6106 - mae: 0.1468 - val_loss: 1.0612 - val_acc: 0.5568 - val_mae: 0.1541 - 247ms/epoch - 747us/step\n",
      "Epoch 46/200\n",
      "330/330 - 0s - loss: 0.8922 - acc: 0.6116 - mae: 0.1460 - val_loss: 1.0970 - val_acc: 0.5659 - val_mae: 0.1536 - 256ms/epoch - 776us/step\n",
      "Epoch 47/200\n",
      "330/330 - 0s - loss: 0.8887 - acc: 0.6121 - mae: 0.1455 - val_loss: 1.0584 - val_acc: 0.5705 - val_mae: 0.1551 - 235ms/epoch - 712us/step\n",
      "Epoch 48/200\n",
      "330/330 - 0s - loss: 0.8797 - acc: 0.6207 - mae: 0.1446 - val_loss: 1.0954 - val_acc: 0.5273 - val_mae: 0.1582 - 250ms/epoch - 758us/step\n",
      "Epoch 49/200\n",
      "330/330 - 0s - loss: 0.8809 - acc: 0.6222 - mae: 0.1442 - val_loss: 1.0611 - val_acc: 0.5682 - val_mae: 0.1534 - 328ms/epoch - 994us/step\n",
      "Epoch 50/200\n",
      "330/330 - 0s - loss: 0.8724 - acc: 0.6212 - mae: 0.1437 - val_loss: 1.0572 - val_acc: 0.5659 - val_mae: 0.1502 - 330ms/epoch - 1000us/step\n",
      "Epoch 51/200\n",
      "330/330 - 0s - loss: 0.8771 - acc: 0.6194 - mae: 0.1437 - val_loss: 1.0801 - val_acc: 0.5636 - val_mae: 0.1518 - 324ms/epoch - 982us/step\n",
      "Epoch 52/200\n",
      "330/330 - 0s - loss: 0.8739 - acc: 0.6197 - mae: 0.1436 - val_loss: 1.0812 - val_acc: 0.5636 - val_mae: 0.1519 - 238ms/epoch - 722us/step\n",
      "Epoch 53/200\n",
      "330/330 - 0s - loss: 0.8603 - acc: 0.6237 - mae: 0.1421 - val_loss: 1.0848 - val_acc: 0.5705 - val_mae: 0.1518 - 294ms/epoch - 891us/step\n",
      "Epoch 54/200\n",
      "330/330 - 0s - loss: 0.8627 - acc: 0.6283 - mae: 0.1419 - val_loss: 1.0912 - val_acc: 0.5795 - val_mae: 0.1504 - 310ms/epoch - 939us/step\n",
      "Epoch 55/200\n",
      "330/330 - 0s - loss: 0.8627 - acc: 0.6212 - mae: 0.1422 - val_loss: 1.0638 - val_acc: 0.5773 - val_mae: 0.1488 - 276ms/epoch - 835us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/200\n",
      "330/330 - 0s - loss: 0.8528 - acc: 0.6358 - mae: 0.1399 - val_loss: 1.0677 - val_acc: 0.5568 - val_mae: 0.1532 - 303ms/epoch - 918us/step\n",
      "Epoch 57/200\n",
      "330/330 - 0s - loss: 0.8512 - acc: 0.6343 - mae: 0.1400 - val_loss: 1.0851 - val_acc: 0.5750 - val_mae: 0.1530 - 271ms/epoch - 822us/step\n",
      "Epoch 58/200\n",
      "330/330 - 0s - loss: 0.8522 - acc: 0.6328 - mae: 0.1402 - val_loss: 1.0638 - val_acc: 0.5886 - val_mae: 0.1469 - 293ms/epoch - 888us/step\n",
      "Epoch 59/200\n",
      "330/330 - 0s - loss: 0.8428 - acc: 0.6346 - mae: 0.1390 - val_loss: 1.1154 - val_acc: 0.5636 - val_mae: 0.1498 - 278ms/epoch - 843us/step\n",
      "Epoch 60/200\n",
      "330/330 - 0s - loss: 0.8400 - acc: 0.6389 - mae: 0.1385 - val_loss: 1.0694 - val_acc: 0.5795 - val_mae: 0.1497 - 264ms/epoch - 800us/step\n",
      "Epoch 61/200\n",
      "330/330 - 0s - loss: 0.8370 - acc: 0.6391 - mae: 0.1385 - val_loss: 1.0576 - val_acc: 0.5750 - val_mae: 0.1469 - 245ms/epoch - 742us/step\n",
      "Epoch 62/200\n",
      "330/330 - 0s - loss: 0.8355 - acc: 0.6351 - mae: 0.1384 - val_loss: 1.0918 - val_acc: 0.5750 - val_mae: 0.1438 - 241ms/epoch - 730us/step\n",
      "Epoch 63/200\n",
      "330/330 - 0s - loss: 0.8347 - acc: 0.6328 - mae: 0.1375 - val_loss: 1.1008 - val_acc: 0.5682 - val_mae: 0.1473 - 249ms/epoch - 755us/step\n",
      "Epoch 64/200\n",
      "330/330 - 0s - loss: 0.8363 - acc: 0.6374 - mae: 0.1381 - val_loss: 1.0601 - val_acc: 0.5750 - val_mae: 0.1494 - 235ms/epoch - 711us/step\n",
      "Epoch 65/200\n",
      "330/330 - 0s - loss: 0.8211 - acc: 0.6452 - mae: 0.1360 - val_loss: 1.0698 - val_acc: 0.5727 - val_mae: 0.1507 - 256ms/epoch - 776us/step\n",
      "Epoch 66/200\n",
      "330/330 - 0s - loss: 0.8179 - acc: 0.6391 - mae: 0.1355 - val_loss: 1.0576 - val_acc: 0.5841 - val_mae: 0.1495 - 234ms/epoch - 710us/step\n",
      "Epoch 67/200\n",
      "330/330 - 0s - loss: 0.8191 - acc: 0.6419 - mae: 0.1361 - val_loss: 1.0603 - val_acc: 0.5932 - val_mae: 0.1466 - 250ms/epoch - 758us/step\n",
      "Epoch 68/200\n",
      "330/330 - 0s - loss: 0.8151 - acc: 0.6477 - mae: 0.1345 - val_loss: 1.0640 - val_acc: 0.5841 - val_mae: 0.1448 - 253ms/epoch - 767us/step\n",
      "Epoch 69/200\n",
      "330/330 - 0s - loss: 0.8115 - acc: 0.6492 - mae: 0.1342 - val_loss: 1.0881 - val_acc: 0.5909 - val_mae: 0.1487 - 247ms/epoch - 748us/step\n",
      "Epoch 70/200\n",
      "330/330 - 0s - loss: 0.8032 - acc: 0.6492 - mae: 0.1338 - val_loss: 1.0534 - val_acc: 0.5955 - val_mae: 0.1472 - 287ms/epoch - 870us/step\n",
      "Epoch 71/200\n",
      "330/330 - 0s - loss: 0.8019 - acc: 0.6555 - mae: 0.1330 - val_loss: 1.0792 - val_acc: 0.5614 - val_mae: 0.1454 - 267ms/epoch - 808us/step\n",
      "Epoch 72/200\n",
      "330/330 - 0s - loss: 0.7997 - acc: 0.6500 - mae: 0.1330 - val_loss: 1.0746 - val_acc: 0.5864 - val_mae: 0.1460 - 244ms/epoch - 738us/step\n",
      "Epoch 73/200\n",
      "330/330 - 0s - loss: 0.7955 - acc: 0.6538 - mae: 0.1320 - val_loss: 1.1013 - val_acc: 0.5864 - val_mae: 0.1455 - 245ms/epoch - 741us/step\n",
      "Epoch 74/200\n",
      "330/330 - 0s - loss: 0.7949 - acc: 0.6614 - mae: 0.1315 - val_loss: 1.1257 - val_acc: 0.5795 - val_mae: 0.1453 - 278ms/epoch - 844us/step\n",
      "Epoch 75/200\n",
      "330/330 - 0s - loss: 0.7882 - acc: 0.6626 - mae: 0.1303 - val_loss: 1.0490 - val_acc: 0.6023 - val_mae: 0.1426 - 241ms/epoch - 731us/step\n",
      "Epoch 76/200\n",
      "330/330 - 0s - loss: 0.7817 - acc: 0.6631 - mae: 0.1299 - val_loss: 1.0724 - val_acc: 0.5864 - val_mae: 0.1463 - 279ms/epoch - 844us/step\n",
      "Epoch 77/200\n",
      "330/330 - 0s - loss: 0.7814 - acc: 0.6583 - mae: 0.1303 - val_loss: 1.1092 - val_acc: 0.5773 - val_mae: 0.1472 - 258ms/epoch - 782us/step\n",
      "Epoch 78/200\n",
      "330/330 - 0s - loss: 0.7770 - acc: 0.6631 - mae: 0.1292 - val_loss: 1.1066 - val_acc: 0.5932 - val_mae: 0.1423 - 248ms/epoch - 752us/step\n",
      "Epoch 79/200\n",
      "330/330 - 0s - loss: 0.7755 - acc: 0.6664 - mae: 0.1293 - val_loss: 1.0985 - val_acc: 0.5864 - val_mae: 0.1384 - 278ms/epoch - 844us/step\n",
      "Epoch 80/200\n",
      "330/330 - 0s - loss: 0.7712 - acc: 0.6662 - mae: 0.1281 - val_loss: 1.0873 - val_acc: 0.6000 - val_mae: 0.1460 - 246ms/epoch - 745us/step\n",
      "Epoch 81/200\n",
      "330/330 - 0s - loss: 0.7698 - acc: 0.6697 - mae: 0.1278 - val_loss: 1.0594 - val_acc: 0.6091 - val_mae: 0.1423 - 294ms/epoch - 892us/step\n",
      "Epoch 82/200\n",
      "330/330 - 0s - loss: 0.7573 - acc: 0.6712 - mae: 0.1262 - val_loss: 1.0946 - val_acc: 0.5818 - val_mae: 0.1422 - 261ms/epoch - 791us/step\n",
      "Epoch 83/200\n",
      "330/330 - 0s - loss: 0.7705 - acc: 0.6672 - mae: 0.1278 - val_loss: 1.0885 - val_acc: 0.5864 - val_mae: 0.1437 - 242ms/epoch - 735us/step\n",
      "Epoch 84/200\n",
      "330/330 - 0s - loss: 0.7543 - acc: 0.6760 - mae: 0.1261 - val_loss: 1.1046 - val_acc: 0.5909 - val_mae: 0.1422 - 244ms/epoch - 739us/step\n",
      "Epoch 85/200\n",
      "330/330 - 0s - loss: 0.7502 - acc: 0.6697 - mae: 0.1255 - val_loss: 1.0842 - val_acc: 0.6045 - val_mae: 0.1452 - 258ms/epoch - 781us/step\n",
      "Epoch 86/200\n",
      "330/330 - 0s - loss: 0.7480 - acc: 0.6758 - mae: 0.1250 - val_loss: 1.1061 - val_acc: 0.5841 - val_mae: 0.1396 - 278ms/epoch - 843us/step\n",
      "Epoch 87/200\n",
      "330/330 - 0s - loss: 0.7419 - acc: 0.6821 - mae: 0.1234 - val_loss: 1.1467 - val_acc: 0.5523 - val_mae: 0.1488 - 233ms/epoch - 707us/step\n",
      "Epoch 88/200\n",
      "330/330 - 0s - loss: 0.7394 - acc: 0.6818 - mae: 0.1236 - val_loss: 1.1192 - val_acc: 0.5886 - val_mae: 0.1447 - 251ms/epoch - 761us/step\n",
      "Epoch 89/200\n",
      "330/330 - 0s - loss: 0.7295 - acc: 0.6887 - mae: 0.1231 - val_loss: 1.1285 - val_acc: 0.5977 - val_mae: 0.1372 - 232ms/epoch - 703us/step\n",
      "Epoch 90/200\n",
      "330/330 - 0s - loss: 0.7297 - acc: 0.6919 - mae: 0.1225 - val_loss: 1.1086 - val_acc: 0.6045 - val_mae: 0.1386 - 278ms/epoch - 843us/step\n",
      "Epoch 91/200\n",
      "330/330 - 0s - loss: 0.7273 - acc: 0.6859 - mae: 0.1210 - val_loss: 1.1114 - val_acc: 0.5841 - val_mae: 0.1417 - 251ms/epoch - 761us/step\n",
      "Epoch 92/200\n",
      "330/330 - 0s - loss: 0.7217 - acc: 0.6869 - mae: 0.1213 - val_loss: 1.1313 - val_acc: 0.5818 - val_mae: 0.1415 - 276ms/epoch - 836us/step\n",
      "Epoch 93/200\n",
      "330/330 - 0s - loss: 0.7138 - acc: 0.6869 - mae: 0.1195 - val_loss: 1.1321 - val_acc: 0.5932 - val_mae: 0.1402 - 257ms/epoch - 777us/step\n",
      "Epoch 94/200\n",
      "330/330 - 0s - loss: 0.7178 - acc: 0.6914 - mae: 0.1200 - val_loss: 1.1573 - val_acc: 0.5864 - val_mae: 0.1387 - 243ms/epoch - 737us/step\n",
      "Epoch 95/200\n",
      "330/330 - 0s - loss: 0.7116 - acc: 0.6917 - mae: 0.1192 - val_loss: 1.1062 - val_acc: 0.6045 - val_mae: 0.1380 - 241ms/epoch - 729us/step\n",
      "Epoch 96/200\n",
      "330/330 - 0s - loss: 0.7098 - acc: 0.6940 - mae: 0.1188 - val_loss: 1.1381 - val_acc: 0.5909 - val_mae: 0.1413 - 255ms/epoch - 771us/step\n",
      "Epoch 97/200\n",
      "330/330 - 0s - loss: 0.7058 - acc: 0.6967 - mae: 0.1184 - val_loss: 1.0882 - val_acc: 0.6136 - val_mae: 0.1386 - 239ms/epoch - 726us/step\n",
      "Epoch 98/200\n",
      "330/330 - 0s - loss: 0.7016 - acc: 0.6967 - mae: 0.1179 - val_loss: 1.1338 - val_acc: 0.5841 - val_mae: 0.1396 - 250ms/epoch - 758us/step\n",
      "Epoch 99/200\n",
      "330/330 - 0s - loss: 0.6908 - acc: 0.7041 - mae: 0.1154 - val_loss: 1.1870 - val_acc: 0.5773 - val_mae: 0.1428 - 237ms/epoch - 719us/step\n",
      "Epoch 100/200\n",
      "330/330 - 0s - loss: 0.6888 - acc: 0.7094 - mae: 0.1160 - val_loss: 1.1448 - val_acc: 0.5818 - val_mae: 0.1425 - 249ms/epoch - 754us/step\n",
      "Epoch 101/200\n",
      "330/330 - 0s - loss: 0.6815 - acc: 0.7051 - mae: 0.1144 - val_loss: 1.1309 - val_acc: 0.6091 - val_mae: 0.1338 - 314ms/epoch - 952us/step\n",
      "Epoch 102/200\n",
      "330/330 - 0s - loss: 0.6771 - acc: 0.7099 - mae: 0.1142 - val_loss: 1.1335 - val_acc: 0.6000 - val_mae: 0.1367 - 318ms/epoch - 962us/step\n",
      "Epoch 103/200\n",
      "330/330 - 0s - loss: 0.6751 - acc: 0.7127 - mae: 0.1136 - val_loss: 1.1801 - val_acc: 0.5886 - val_mae: 0.1376 - 317ms/epoch - 961us/step\n",
      "Epoch 104/200\n",
      "330/330 - 0s - loss: 0.6805 - acc: 0.7132 - mae: 0.1134 - val_loss: 1.1920 - val_acc: 0.5886 - val_mae: 0.1392 - 454ms/epoch - 1ms/step\n",
      "Epoch 105/200\n",
      "330/330 - 1s - loss: 0.6718 - acc: 0.7142 - mae: 0.1127 - val_loss: 1.1706 - val_acc: 0.5977 - val_mae: 0.1374 - 501ms/epoch - 2ms/step\n",
      "Epoch 106/200\n",
      "330/330 - 1s - loss: 0.6589 - acc: 0.7205 - mae: 0.1114 - val_loss: 1.2762 - val_acc: 0.5500 - val_mae: 0.1423 - 547ms/epoch - 2ms/step\n",
      "Epoch 107/200\n",
      "330/330 - 1s - loss: 0.6614 - acc: 0.7149 - mae: 0.1111 - val_loss: 1.2159 - val_acc: 0.5773 - val_mae: 0.1403 - 546ms/epoch - 2ms/step\n",
      "Epoch 108/200\n",
      "330/330 - 1s - loss: 0.6652 - acc: 0.7154 - mae: 0.1111 - val_loss: 1.1818 - val_acc: 0.5818 - val_mae: 0.1410 - 592ms/epoch - 2ms/step\n",
      "Epoch 109/200\n",
      "330/330 - 1s - loss: 0.6508 - acc: 0.7321 - mae: 0.1094 - val_loss: 1.2078 - val_acc: 0.5773 - val_mae: 0.1370 - 550ms/epoch - 2ms/step\n",
      "Epoch 110/200\n",
      "330/330 - 0s - loss: 0.6601 - acc: 0.7104 - mae: 0.1106 - val_loss: 1.2406 - val_acc: 0.5659 - val_mae: 0.1393 - 425ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/200\n",
      "330/330 - 1s - loss: 0.6507 - acc: 0.7255 - mae: 0.1093 - val_loss: 1.2382 - val_acc: 0.5773 - val_mae: 0.1366 - 541ms/epoch - 2ms/step\n",
      "Epoch 112/200\n",
      "330/330 - 0s - loss: 0.6329 - acc: 0.7420 - mae: 0.1069 - val_loss: 1.2293 - val_acc: 0.5750 - val_mae: 0.1373 - 399ms/epoch - 1ms/step\n",
      "Epoch 113/200\n",
      "330/330 - 0s - loss: 0.6313 - acc: 0.7321 - mae: 0.1071 - val_loss: 1.2229 - val_acc: 0.5818 - val_mae: 0.1347 - 401ms/epoch - 1ms/step\n",
      "Epoch 114/200\n",
      "330/330 - 0s - loss: 0.6427 - acc: 0.7329 - mae: 0.1068 - val_loss: 1.1960 - val_acc: 0.6182 - val_mae: 0.1341 - 250ms/epoch - 756us/step\n",
      "Epoch 115/200\n",
      "330/330 - 0s - loss: 0.6304 - acc: 0.7354 - mae: 0.1061 - val_loss: 1.2003 - val_acc: 0.5773 - val_mae: 0.1369 - 250ms/epoch - 759us/step\n",
      "Epoch 116/200\n",
      "330/330 - 0s - loss: 0.6250 - acc: 0.7319 - mae: 0.1057 - val_loss: 1.1804 - val_acc: 0.5955 - val_mae: 0.1326 - 244ms/epoch - 740us/step\n",
      "Epoch 117/200\n",
      "330/330 - 0s - loss: 0.6287 - acc: 0.7412 - mae: 0.1053 - val_loss: 1.2676 - val_acc: 0.5795 - val_mae: 0.1361 - 247ms/epoch - 747us/step\n",
      "Epoch 118/200\n",
      "330/330 - 0s - loss: 0.6129 - acc: 0.7405 - mae: 0.1035 - val_loss: 1.2576 - val_acc: 0.5591 - val_mae: 0.1432 - 393ms/epoch - 1ms/step\n",
      "Epoch 119/200\n",
      "330/330 - 0s - loss: 0.6196 - acc: 0.7412 - mae: 0.1042 - val_loss: 1.2484 - val_acc: 0.5909 - val_mae: 0.1327 - 265ms/epoch - 803us/step\n",
      "Epoch 120/200\n",
      "330/330 - 0s - loss: 0.6109 - acc: 0.7379 - mae: 0.1032 - val_loss: 1.2219 - val_acc: 0.5886 - val_mae: 0.1374 - 416ms/epoch - 1ms/step\n",
      "Epoch 121/200\n",
      "330/330 - 0s - loss: 0.5989 - acc: 0.7443 - mae: 0.1020 - val_loss: 1.2613 - val_acc: 0.5773 - val_mae: 0.1369 - 269ms/epoch - 815us/step\n",
      "Epoch 122/200\n",
      "330/330 - 0s - loss: 0.6005 - acc: 0.7485 - mae: 0.1013 - val_loss: 1.2339 - val_acc: 0.5659 - val_mae: 0.1360 - 333ms/epoch - 1ms/step\n",
      "Epoch 123/200\n",
      "330/330 - 0s - loss: 0.6113 - acc: 0.7397 - mae: 0.1024 - val_loss: 1.2458 - val_acc: 0.6091 - val_mae: 0.1299 - 237ms/epoch - 718us/step\n",
      "Epoch 124/200\n",
      "330/330 - 0s - loss: 0.5953 - acc: 0.7488 - mae: 0.1003 - val_loss: 1.2457 - val_acc: 0.5932 - val_mae: 0.1313 - 257ms/epoch - 778us/step\n",
      "Epoch 125/200\n",
      "330/330 - 0s - loss: 0.5888 - acc: 0.7574 - mae: 0.0995 - val_loss: 1.2751 - val_acc: 0.5977 - val_mae: 0.1344 - 231ms/epoch - 700us/step\n",
      "Epoch 126/200\n",
      "330/330 - 0s - loss: 0.5885 - acc: 0.7571 - mae: 0.0987 - val_loss: 1.2938 - val_acc: 0.5909 - val_mae: 0.1363 - 258ms/epoch - 783us/step\n",
      "Epoch 127/200\n",
      "330/330 - 0s - loss: 0.5746 - acc: 0.7569 - mae: 0.0977 - val_loss: 1.2698 - val_acc: 0.5864 - val_mae: 0.1376 - 290ms/epoch - 879us/step\n",
      "Epoch 128/200\n",
      "330/330 - 0s - loss: 0.5981 - acc: 0.7420 - mae: 0.1002 - val_loss: 1.2549 - val_acc: 0.5750 - val_mae: 0.1321 - 367ms/epoch - 1ms/step\n",
      "Epoch 129/200\n",
      "330/330 - 0s - loss: 0.5781 - acc: 0.7602 - mae: 0.0974 - val_loss: 1.2682 - val_acc: 0.5727 - val_mae: 0.1363 - 241ms/epoch - 729us/step\n",
      "Epoch 130/200\n",
      "330/330 - 0s - loss: 0.5736 - acc: 0.7556 - mae: 0.0973 - val_loss: 1.3229 - val_acc: 0.5773 - val_mae: 0.1349 - 241ms/epoch - 729us/step\n",
      "Epoch 131/200\n",
      "330/330 - 0s - loss: 0.5727 - acc: 0.7607 - mae: 0.0968 - val_loss: 1.3199 - val_acc: 0.5864 - val_mae: 0.1329 - 248ms/epoch - 751us/step\n",
      "Epoch 132/200\n",
      "330/330 - 0s - loss: 0.5770 - acc: 0.7630 - mae: 0.0968 - val_loss: 1.3543 - val_acc: 0.5682 - val_mae: 0.1344 - 248ms/epoch - 751us/step\n",
      "Epoch 133/200\n",
      "330/330 - 0s - loss: 0.5740 - acc: 0.7614 - mae: 0.0960 - val_loss: 1.2789 - val_acc: 0.6000 - val_mae: 0.1318 - 254ms/epoch - 771us/step\n",
      "Epoch 134/200\n",
      "330/330 - 0s - loss: 0.5563 - acc: 0.7670 - mae: 0.0941 - val_loss: 1.2800 - val_acc: 0.5705 - val_mae: 0.1321 - 249ms/epoch - 754us/step\n",
      "Epoch 135/200\n",
      "330/330 - 0s - loss: 0.5572 - acc: 0.7688 - mae: 0.0937 - val_loss: 1.3004 - val_acc: 0.5909 - val_mae: 0.1340 - 279ms/epoch - 847us/step\n",
      "Epoch 136/200\n",
      "330/330 - 1s - loss: 0.5557 - acc: 0.7675 - mae: 0.0945 - val_loss: 1.3043 - val_acc: 0.5977 - val_mae: 0.1312 - 518ms/epoch - 2ms/step\n",
      "Epoch 137/200\n",
      "330/330 - 0s - loss: 0.5558 - acc: 0.7683 - mae: 0.0937 - val_loss: 1.3113 - val_acc: 0.5864 - val_mae: 0.1311 - 405ms/epoch - 1ms/step\n",
      "Epoch 138/200\n",
      "330/330 - 1s - loss: 0.5524 - acc: 0.7665 - mae: 0.0930 - val_loss: 1.3593 - val_acc: 0.5841 - val_mae: 0.1341 - 534ms/epoch - 2ms/step\n",
      "Epoch 139/200\n",
      "330/330 - 0s - loss: 0.5413 - acc: 0.7769 - mae: 0.0915 - val_loss: 1.3500 - val_acc: 0.6068 - val_mae: 0.1299 - 274ms/epoch - 830us/step\n",
      "Epoch 140/200\n",
      "330/330 - 0s - loss: 0.5324 - acc: 0.7885 - mae: 0.0902 - val_loss: 1.3580 - val_acc: 0.5932 - val_mae: 0.1314 - 289ms/epoch - 876us/step\n",
      "Epoch 141/200\n",
      "330/330 - 1s - loss: 0.5372 - acc: 0.7796 - mae: 0.0904 - val_loss: 1.3246 - val_acc: 0.6000 - val_mae: 0.1288 - 520ms/epoch - 2ms/step\n",
      "Epoch 142/200\n",
      "330/330 - 0s - loss: 0.5392 - acc: 0.7769 - mae: 0.0910 - val_loss: 1.3616 - val_acc: 0.5614 - val_mae: 0.1386 - 409ms/epoch - 1ms/step\n",
      "Epoch 143/200\n",
      "330/330 - 0s - loss: 0.5282 - acc: 0.7859 - mae: 0.0899 - val_loss: 1.3977 - val_acc: 0.6136 - val_mae: 0.1293 - 395ms/epoch - 1ms/step\n",
      "Epoch 144/200\n",
      "330/330 - 0s - loss: 0.5366 - acc: 0.7728 - mae: 0.0901 - val_loss: 1.3263 - val_acc: 0.5909 - val_mae: 0.1304 - 246ms/epoch - 744us/step\n",
      "Epoch 145/200\n",
      "330/330 - 0s - loss: 0.5304 - acc: 0.7865 - mae: 0.0886 - val_loss: 1.3870 - val_acc: 0.5477 - val_mae: 0.1377 - 404ms/epoch - 1ms/step\n",
      "Epoch 146/200\n",
      "330/330 - 0s - loss: 0.5215 - acc: 0.7867 - mae: 0.0882 - val_loss: 1.3661 - val_acc: 0.5795 - val_mae: 0.1281 - 240ms/epoch - 728us/step\n",
      "Epoch 147/200\n",
      "330/330 - 0s - loss: 0.5092 - acc: 0.7854 - mae: 0.0864 - val_loss: 1.4747 - val_acc: 0.5705 - val_mae: 0.1361 - 418ms/epoch - 1ms/step\n",
      "Epoch 148/200\n",
      "330/330 - 0s - loss: 0.5188 - acc: 0.7875 - mae: 0.0880 - val_loss: 1.3239 - val_acc: 0.6091 - val_mae: 0.1287 - 249ms/epoch - 753us/step\n",
      "Epoch 149/200\n",
      "330/330 - 0s - loss: 0.5224 - acc: 0.7887 - mae: 0.0878 - val_loss: 1.3725 - val_acc: 0.5977 - val_mae: 0.1249 - 237ms/epoch - 718us/step\n",
      "Epoch 150/200\n",
      "330/330 - 0s - loss: 0.5054 - acc: 0.7966 - mae: 0.0855 - val_loss: 1.4237 - val_acc: 0.5818 - val_mae: 0.1299 - 252ms/epoch - 764us/step\n",
      "Epoch 151/200\n",
      "330/330 - 0s - loss: 0.5106 - acc: 0.7925 - mae: 0.0860 - val_loss: 1.4155 - val_acc: 0.5886 - val_mae: 0.1286 - 242ms/epoch - 733us/step\n",
      "Epoch 152/200\n",
      "330/330 - 0s - loss: 0.4972 - acc: 0.8009 - mae: 0.0842 - val_loss: 1.3680 - val_acc: 0.5955 - val_mae: 0.1255 - 244ms/epoch - 739us/step\n",
      "Epoch 153/200\n",
      "330/330 - 0s - loss: 0.4955 - acc: 0.7940 - mae: 0.0842 - val_loss: 1.4407 - val_acc: 0.5977 - val_mae: 0.1288 - 274ms/epoch - 830us/step\n",
      "Epoch 154/200\n",
      "330/330 - 0s - loss: 0.4981 - acc: 0.8006 - mae: 0.0844 - val_loss: 1.4163 - val_acc: 0.5955 - val_mae: 0.1284 - 318ms/epoch - 964us/step\n",
      "Epoch 155/200\n",
      "330/330 - 0s - loss: 0.4897 - acc: 0.8011 - mae: 0.0833 - val_loss: 1.5087 - val_acc: 0.5705 - val_mae: 0.1347 - 250ms/epoch - 758us/step\n",
      "Epoch 156/200\n",
      "330/330 - 0s - loss: 0.5045 - acc: 0.7935 - mae: 0.0842 - val_loss: 1.4673 - val_acc: 0.5773 - val_mae: 0.1319 - 348ms/epoch - 1ms/step\n",
      "Epoch 157/200\n",
      "330/330 - 0s - loss: 0.4886 - acc: 0.7991 - mae: 0.0826 - val_loss: 1.3815 - val_acc: 0.5841 - val_mae: 0.1326 - 318ms/epoch - 965us/step\n",
      "Epoch 158/200\n",
      "330/330 - 0s - loss: 0.4930 - acc: 0.7998 - mae: 0.0833 - val_loss: 1.4673 - val_acc: 0.6091 - val_mae: 0.1268 - 411ms/epoch - 1ms/step\n",
      "Epoch 159/200\n",
      "330/330 - 0s - loss: 0.4877 - acc: 0.8057 - mae: 0.0822 - val_loss: 1.4661 - val_acc: 0.6091 - val_mae: 0.1264 - 390ms/epoch - 1ms/step\n",
      "Epoch 160/200\n",
      "330/330 - 0s - loss: 0.4703 - acc: 0.8089 - mae: 0.0800 - val_loss: 1.4315 - val_acc: 0.5955 - val_mae: 0.1255 - 414ms/epoch - 1ms/step\n",
      "Epoch 161/200\n",
      "330/330 - 0s - loss: 0.4846 - acc: 0.8011 - mae: 0.0812 - val_loss: 1.5498 - val_acc: 0.5864 - val_mae: 0.1341 - 393ms/epoch - 1ms/step\n",
      "Epoch 162/200\n",
      "330/330 - 0s - loss: 0.4672 - acc: 0.8110 - mae: 0.0794 - val_loss: 1.4950 - val_acc: 0.6023 - val_mae: 0.1242 - 302ms/epoch - 914us/step\n",
      "Epoch 163/200\n",
      "330/330 - 0s - loss: 0.4691 - acc: 0.8074 - mae: 0.0793 - val_loss: 1.5304 - val_acc: 0.5818 - val_mae: 0.1266 - 374ms/epoch - 1ms/step\n",
      "Epoch 164/200\n",
      "330/330 - 0s - loss: 0.4648 - acc: 0.8178 - mae: 0.0786 - val_loss: 1.5633 - val_acc: 0.5977 - val_mae: 0.1273 - 426ms/epoch - 1ms/step\n",
      "Epoch 165/200\n",
      "330/330 - 0s - loss: 0.4676 - acc: 0.8130 - mae: 0.0787 - val_loss: 1.4596 - val_acc: 0.5886 - val_mae: 0.1307 - 421ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/200\n",
      "330/330 - 0s - loss: 0.4652 - acc: 0.8137 - mae: 0.0789 - val_loss: 1.5504 - val_acc: 0.5795 - val_mae: 0.1297 - 443ms/epoch - 1ms/step\n",
      "Epoch 167/200\n",
      "330/330 - 0s - loss: 0.4737 - acc: 0.8127 - mae: 0.0791 - val_loss: 1.5510 - val_acc: 0.6114 - val_mae: 0.1286 - 409ms/epoch - 1ms/step\n",
      "Epoch 168/200\n",
      "330/330 - 1s - loss: 0.4556 - acc: 0.8196 - mae: 0.0775 - val_loss: 1.5048 - val_acc: 0.5864 - val_mae: 0.1257 - 538ms/epoch - 2ms/step\n",
      "Epoch 169/200\n",
      "330/330 - 0s - loss: 0.4643 - acc: 0.8158 - mae: 0.0781 - val_loss: 1.4806 - val_acc: 0.5886 - val_mae: 0.1307 - 438ms/epoch - 1ms/step\n",
      "Epoch 170/200\n",
      "330/330 - 0s - loss: 0.4566 - acc: 0.8160 - mae: 0.0779 - val_loss: 1.5014 - val_acc: 0.6091 - val_mae: 0.1234 - 428ms/epoch - 1ms/step\n",
      "Epoch 171/200\n",
      "330/330 - 0s - loss: 0.4413 - acc: 0.8208 - mae: 0.0755 - val_loss: 1.5356 - val_acc: 0.5841 - val_mae: 0.1302 - 408ms/epoch - 1ms/step\n",
      "Epoch 172/200\n",
      "330/330 - 0s - loss: 0.4532 - acc: 0.8198 - mae: 0.0765 - val_loss: 1.5462 - val_acc: 0.6091 - val_mae: 0.1223 - 360ms/epoch - 1ms/step\n",
      "Epoch 173/200\n",
      "330/330 - 0s - loss: 0.4371 - acc: 0.8259 - mae: 0.0744 - val_loss: 1.5817 - val_acc: 0.6205 - val_mae: 0.1236 - 322ms/epoch - 976us/step\n",
      "Epoch 174/200\n",
      "330/330 - 0s - loss: 0.4481 - acc: 0.8175 - mae: 0.0752 - val_loss: 1.5695 - val_acc: 0.5705 - val_mae: 0.1290 - 275ms/epoch - 833us/step\n",
      "Epoch 175/200\n",
      "330/330 - 0s - loss: 0.4559 - acc: 0.8127 - mae: 0.0758 - val_loss: 1.5182 - val_acc: 0.6091 - val_mae: 0.1252 - 269ms/epoch - 816us/step\n",
      "Epoch 176/200\n",
      "330/330 - 0s - loss: 0.4248 - acc: 0.8254 - mae: 0.0735 - val_loss: 1.5467 - val_acc: 0.6091 - val_mae: 0.1251 - 316ms/epoch - 958us/step\n",
      "Epoch 177/200\n",
      "330/330 - 0s - loss: 0.4423 - acc: 0.8251 - mae: 0.0742 - val_loss: 1.6181 - val_acc: 0.5955 - val_mae: 0.1255 - 289ms/epoch - 874us/step\n",
      "Epoch 178/200\n",
      "330/330 - 0s - loss: 0.4258 - acc: 0.8251 - mae: 0.0725 - val_loss: 1.5824 - val_acc: 0.6023 - val_mae: 0.1255 - 397ms/epoch - 1ms/step\n",
      "Epoch 179/200\n",
      "330/330 - 0s - loss: 0.4228 - acc: 0.8362 - mae: 0.0718 - val_loss: 1.6946 - val_acc: 0.5705 - val_mae: 0.1326 - 366ms/epoch - 1ms/step\n",
      "Epoch 180/200\n",
      "330/330 - 0s - loss: 0.4405 - acc: 0.8193 - mae: 0.0738 - val_loss: 1.5708 - val_acc: 0.5932 - val_mae: 0.1268 - 454ms/epoch - 1ms/step\n",
      "Epoch 181/200\n",
      "330/330 - 0s - loss: 0.4248 - acc: 0.8274 - mae: 0.0717 - val_loss: 1.5910 - val_acc: 0.5909 - val_mae: 0.1259 - 244ms/epoch - 740us/step\n",
      "Epoch 182/200\n",
      "330/330 - 0s - loss: 0.4182 - acc: 0.8337 - mae: 0.0707 - val_loss: 1.5441 - val_acc: 0.6091 - val_mae: 0.1280 - 236ms/epoch - 716us/step\n",
      "Epoch 183/200\n",
      "330/330 - 0s - loss: 0.4199 - acc: 0.8355 - mae: 0.0709 - val_loss: 1.6286 - val_acc: 0.5886 - val_mae: 0.1258 - 348ms/epoch - 1ms/step\n",
      "Epoch 184/200\n",
      "330/330 - 0s - loss: 0.4210 - acc: 0.8317 - mae: 0.0710 - val_loss: 1.6126 - val_acc: 0.6000 - val_mae: 0.1229 - 302ms/epoch - 916us/step\n",
      "Epoch 185/200\n",
      "330/330 - 0s - loss: 0.4128 - acc: 0.8370 - mae: 0.0698 - val_loss: 1.5804 - val_acc: 0.5955 - val_mae: 0.1263 - 327ms/epoch - 991us/step\n",
      "Epoch 186/200\n",
      "330/330 - 0s - loss: 0.4117 - acc: 0.8362 - mae: 0.0693 - val_loss: 1.6817 - val_acc: 0.5955 - val_mae: 0.1255 - 285ms/epoch - 864us/step\n",
      "Epoch 187/200\n",
      "330/330 - 0s - loss: 0.4103 - acc: 0.8309 - mae: 0.0694 - val_loss: 1.6375 - val_acc: 0.5886 - val_mae: 0.1288 - 280ms/epoch - 848us/step\n",
      "Epoch 188/200\n",
      "330/330 - 0s - loss: 0.3961 - acc: 0.8456 - mae: 0.0675 - val_loss: 1.6282 - val_acc: 0.5864 - val_mae: 0.1261 - 283ms/epoch - 856us/step\n",
      "Epoch 189/200\n",
      "330/330 - 0s - loss: 0.4137 - acc: 0.8342 - mae: 0.0692 - val_loss: 1.6457 - val_acc: 0.5864 - val_mae: 0.1277 - 235ms/epoch - 712us/step\n",
      "Epoch 190/200\n",
      "330/330 - 0s - loss: 0.4151 - acc: 0.8287 - mae: 0.0699 - val_loss: 1.6183 - val_acc: 0.6227 - val_mae: 0.1228 - 245ms/epoch - 744us/step\n",
      "Epoch 191/200\n",
      "330/330 - 0s - loss: 0.3971 - acc: 0.8461 - mae: 0.0672 - val_loss: 1.7315 - val_acc: 0.5659 - val_mae: 0.1289 - 319ms/epoch - 967us/step\n",
      "Epoch 192/200\n",
      "330/330 - 0s - loss: 0.4054 - acc: 0.8352 - mae: 0.0687 - val_loss: 1.6119 - val_acc: 0.6000 - val_mae: 0.1221 - 344ms/epoch - 1ms/step\n",
      "Epoch 193/200\n",
      "330/330 - 0s - loss: 0.4244 - acc: 0.8297 - mae: 0.0692 - val_loss: 1.7632 - val_acc: 0.5727 - val_mae: 0.1327 - 239ms/epoch - 724us/step\n",
      "Epoch 194/200\n",
      "330/330 - 0s - loss: 0.4009 - acc: 0.8433 - mae: 0.0683 - val_loss: 1.6986 - val_acc: 0.5955 - val_mae: 0.1241 - 261ms/epoch - 791us/step\n",
      "Epoch 195/200\n",
      "330/330 - 0s - loss: 0.3998 - acc: 0.8421 - mae: 0.0674 - val_loss: 1.7301 - val_acc: 0.5932 - val_mae: 0.1286 - 366ms/epoch - 1ms/step\n",
      "Epoch 196/200\n",
      "330/330 - 0s - loss: 0.3826 - acc: 0.8522 - mae: 0.0654 - val_loss: 1.6897 - val_acc: 0.6000 - val_mae: 0.1257 - 359ms/epoch - 1ms/step\n",
      "Epoch 197/200\n",
      "330/330 - 0s - loss: 0.4148 - acc: 0.8400 - mae: 0.0679 - val_loss: 1.6976 - val_acc: 0.5841 - val_mae: 0.1250 - 254ms/epoch - 770us/step\n",
      "Epoch 198/200\n",
      "330/330 - 0s - loss: 0.3826 - acc: 0.8519 - mae: 0.0653 - val_loss: 1.7743 - val_acc: 0.5727 - val_mae: 0.1265 - 362ms/epoch - 1ms/step\n",
      "Epoch 199/200\n",
      "330/330 - 0s - loss: 0.3784 - acc: 0.8547 - mae: 0.0647 - val_loss: 1.7893 - val_acc: 0.5864 - val_mae: 0.1240 - 263ms/epoch - 796us/step\n",
      "Epoch 200/200\n",
      "330/330 - 0s - loss: 0.3814 - acc: 0.8529 - mae: 0.0641 - val_loss: 1.6803 - val_acc: 0.5977 - val_mae: 0.1224 - 337ms/epoch - 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# fit시켜보자\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='acc',  patience=10)\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.1, \n",
    "                                            shuffle=True, random_state=200)\n",
    "\n",
    "history = model.fit(X_tr, y_tr, \n",
    "                    batch_size=12, \n",
    "                    epochs=200,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[early_stopping],                    \n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccefae62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 1ms/step - loss: 1.6803 - acc: 0.5977 - mae: 0.1224\n",
      "loss>>  1.6803290843963623\n",
      "acc>>  0.5977272987365723\n"
     ]
    }
   ],
   "source": [
    "# test데이터로 예측하여 정확도 체크해볼 것.\n",
    "loss, acc, _ = model.evaluate(X_val, y_val)\n",
    "print('loss>> ', loss)\n",
    "print('acc>> ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "239bcf23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.9908962e-04, 1.7439916e-03, 2.2113238e-02, 4.4795895e-01,\n",
       "        4.6489593e-01, 6.2681712e-02, 2.0717790e-04],\n",
       "       [5.3232320e-04, 2.8902534e-03, 6.0239252e-02, 6.1683446e-01,\n",
       "        2.7107009e-01, 4.8269745e-02, 1.6388914e-04],\n",
       "       [1.3265494e-03, 9.4166556e-03, 1.1224672e-01, 6.1695427e-01,\n",
       "        2.3096366e-01, 2.8906524e-02, 1.8567046e-04],\n",
       "       [8.5712934e-04, 6.7214039e-03, 1.1710508e-01, 6.2170535e-01,\n",
       "        2.1984883e-01, 3.3434939e-02, 3.2735476e-04],\n",
       "       [7.9604232e-04, 1.1616648e-02, 5.9126616e-01, 3.7732700e-01,\n",
       "        1.8006152e-02, 9.8795316e-04, 9.1759219e-08]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test 데이터에 대한 예측값 정리\n",
    "y_pred_proba = model.predict(X_test)\n",
    "y_pred_proba[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0d93926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 6, 6, 6, 5], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_label = np.argmax(y_pred_proba, axis=-1) + 3\n",
    "y_pred_label[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fce81bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1100,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49a00ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1100, 7)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cfd64332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 5, 5, ..., 6, 7, 8], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test2 = np.argmax(y_test, axis=-1) + 3\n",
    "y_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94996d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5554545454545454\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "print(accuracy_score(y_test2, y_pred_label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
